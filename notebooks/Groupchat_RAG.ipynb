{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "298baee7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total reviews: 2438577\n",
      "shape: (5, 4)\n",
      "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”\n",
      "â”‚ review_id â”† review_topic â”† review                          â”† score â”‚\n",
      "â”‚ ---       â”† ---          â”† ---                             â”† ---   â”‚\n",
      "â”‚ u32       â”† str          â”† str                             â”† f64   â”‚\n",
      "â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡\n",
      "â”‚ 0         â”† ComputerGame â”† Best ğŸ‘Œ mobile game ever        â”† 5.0   â”‚\n",
      "â”‚ 1         â”† ComputerGame â”† It's a really good game I'm goâ€¦ â”† 5.0   â”‚\n",
      "â”‚ 2         â”† ComputerGame â”† Call of duty mobile is a very â€¦ â”† 5.0   â”‚\n",
      "â”‚ 3         â”† ComputerGame â”† I love the game in it's entireâ€¦ â”† 3.0   â”‚\n",
      "â”‚ 4         â”† ComputerGame â”† Unplayable size.... its portabâ€¦ â”† 1.0   â”‚\n",
      "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”˜\n"
     ]
    }
   ],
   "source": [
    "## STEP 2A â€” Create Retrieval Documents\n",
    "\n",
    "import polars as pl\n",
    "\n",
    "# Load dataset (same as Project 4)\n",
    "df = pl.read_csv(\n",
    "    r\"E:\\__PROJECTS__\\resume projects-data analyst\\genai-multi-agent-project\\data\\raw\\reviews.csv\"\n",
    ")\n",
    "\n",
    "reviews_df = (\n",
    "    df\n",
    "    .select([\n",
    "        pl.col(\"review_topic\"),\n",
    "        pl.col(\"review\"),\n",
    "        pl.col(\"score\")\n",
    "    ])\n",
    "    .with_row_index(\"review_id\")\n",
    "    .filter(pl.col(\"review\").is_not_null())\n",
    ")\n",
    "\n",
    "print(\"Total reviews:\", reviews_df.shape[0])\n",
    "print(reviews_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "58e0bcc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5,)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>review_topic</th></tr><tr><td>str</td></tr></thead><tbody><tr><td>&quot;ComputerGame&quot;</td></tr><tr><td>&quot;Music&quot;</td></tr><tr><td>&quot;Products&quot;</td></tr><tr><td>&quot;Course&quot;</td></tr><tr><td>&quot;Food&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5,)\n",
       "Series: 'review_topic' [str]\n",
       "[\n",
       "\t\"ComputerGame\"\n",
       "\t\"Music\"\n",
       "\t\"Products\"\n",
       "\t\"Course\"\n",
       "\t\"Food\"\n",
       "]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_df['review_topic'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d42fe738",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample document:\n",
      "Review Topic: ComputerGame\n",
      "Score: 5.0\n",
      "Review Text: Best ğŸ‘Œ mobile game ever\n"
     ]
    }
   ],
   "source": [
    "## STEP 2B â€” Convert Reviews into Retrieval Text Blocks\n",
    "\n",
    "def build_review_document(row):\n",
    "    return (\n",
    "        f\"Review Topic: {row['review_topic']}\\n\"\n",
    "        f\"Score: {row['score']}\\n\"\n",
    "        f\"Review Text: {row['review']}\"\n",
    "    )\n",
    "\n",
    "# Sample documents (do NOT embed all 2.4M yet)\n",
    "sample_docs = (\n",
    "    reviews_df\n",
    "    .select([\"review_id\", \"review_topic\", \"score\", \"review\"])\n",
    "    .head(5000)  # start small for testing\n",
    ")\n",
    "\n",
    "documents = [\n",
    "    {\n",
    "        \"id\": int(row[\"review_id\"]),\n",
    "        \"text\": build_review_document(row)\n",
    "    }\n",
    "    for row in sample_docs.to_dicts()\n",
    "]\n",
    "\n",
    "print(\"Sample document:\")\n",
    "print(documents[0][\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c7eb90",
   "metadata": {},
   "source": [
    "## STEP 3 â€” VECTOR STORE CREATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe6a8d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install langchain langchain-openai chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13be065e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install langchain-community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "81bd4d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Add metadata filtering (core change)\n",
    "def filter_reviews_by_topic(df: pl.DataFrame, topic: str) -> pl.DataFrame:\n",
    "    filtered = df.filter(pl.col(\"review_topic\") == topic)\n",
    "\n",
    "    if filtered.height == 0:\n",
    "        print(\"[Retriever] No reviews found for topic. Falling back to full dataset.\")\n",
    "        return df\n",
    "\n",
    "    print(f\"[Retriever] Using {filtered.height} reviews for topic='{topic}'\")\n",
    "    return filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c46ece18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documents prepared for vector store: 1000\n"
     ]
    }
   ],
   "source": [
    "## STEP 3A â€” Create Embeddings + Vector Store\n",
    "\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "# Convert our documents into LangChain Documents\n",
    "langchain_docs = [\n",
    "    Document(\n",
    "        page_content=doc[\"text\"],\n",
    "        metadata={\"review_id\": doc[\"id\"]}\n",
    "    )\n",
    "    for doc in documents\n",
    "]\n",
    "\n",
    "print(\"Documents prepared for vector store:\", len(langchain_docs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05d273b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9912dd5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -U langchain-huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "684d8a3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading weights: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 103/103 [00:00<00:00, 223.65it/s, Materializing param=pooler.dense.weight]                             \n",
      "\u001b[1mBertModel LOAD REPORT\u001b[0m from: sentence-transformers/all-MiniLM-L6-v2\n",
      "Key                     | Status     |  | \n",
      "------------------------+------------+--+-\n",
      "embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "\u001b[3mNotes:\n",
      "- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "## STEP 3B â€” Build the Vector Store\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"all-MiniLM-L6-v2\"  # Free, lightweight model\n",
    ")\n",
    "\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=langchain_docs,\n",
    "    embedding=embeddings,\n",
    "    collection_name=\"review_rag_test\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6fe4a0a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Result 1\n",
      "Review Topic: ComputerGame\n",
      "Score: 5.0\n",
      "Review Text: The best mobile game in the world\n",
      "\n",
      "Result 2\n",
      "Review Topic: ComputerGame\n",
      "Score: 5.0\n",
      "Review Text: The best mobile game in the world\n",
      "\n",
      "Result 3\n",
      "Review Topic: ComputerGame\n",
      "Score: 5.0\n",
      "Review Text: The best mobile game in the world\n"
     ]
    }
   ],
   "source": [
    "## STEP 3C â€” Test Retrieval\n",
    "\n",
    "query = \"complaints about mobile games\"\n",
    "\n",
    "results = vectorstore.similarity_search(query, k=3)\n",
    "\n",
    "for i, res in enumerate(results, 1):\n",
    "    print(f\"\\nResult {i}\")\n",
    "    print(res.page_content[:300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0615e2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## STEP 3D â€” Add HARD NEGATIVE FILTERING\n",
    "def build_review_document(row):\n",
    "    sentiment_hint = (\n",
    "        \"Negative review\"\n",
    "        if row[\"score\"] <= 2.0\n",
    "        else \"Neutral review\" if row[\"score\"] <= 3.0 else \"Positive review\"\n",
    "    )\n",
    "\n",
    "    return (\n",
    "        f\"Review Type: {sentiment_hint}\\n\"\n",
    "        f\"Review Topic: {row['review_topic']}\\n\"\n",
    "        f\"Score: {row['score']}\\n\"\n",
    "        f\"Review Text: {row['review']}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "86959989",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 3E.0 â€” Define query topic (manual for now)\n",
    "query_topic = \"ComputerGame\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f25488ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Retriever] Using 50000 reviews for topic='ComputerGame'\n",
      "Total stratified documents: 5000\n"
     ]
    }
   ],
   "source": [
    "# STEP 3E â€” Rebuild SAMPLE DOCUMENTS (Topic + Sentiment aware)\n",
    "\n",
    "topic_df = filter_reviews_by_topic(reviews_df, query_topic)\n",
    "\n",
    "complaint_docs = (\n",
    "    topic_df.filter(pl.col(\"score\") <= 2.0)\n",
    "    .select([\"review_id\", \"review_topic\", \"score\", \"review\"])\n",
    "    .head(3000)\n",
    ")\n",
    "\n",
    "neutral_docs = (\n",
    "    topic_df.filter(pl.col(\"score\") == 3.0)\n",
    "    .select([\"review_id\", \"review_topic\", \"score\", \"review\"])\n",
    "    .head(1000)\n",
    ")\n",
    "\n",
    "positive_docs = (\n",
    "    topic_df.filter(pl.col(\"score\") >= 4.0)\n",
    "    .select([\"review_id\", \"review_topic\", \"score\", \"review\"])\n",
    "    .head(1000)\n",
    ")\n",
    "\n",
    "sample_docs = pl.concat([complaint_docs, neutral_docs, positive_docs])\n",
    "\n",
    "# Safety fallback\n",
    "if sample_docs.height == 0:\n",
    "    print(\"[WARN] No documents found after filtering. Falling back to full dataset.\")\n",
    "    sample_docs = reviews_df.select(\n",
    "        [\"review_id\", \"review_topic\", \"score\", \"review\"]\n",
    "    ).head(3000)\n",
    "\n",
    "# âœ… SINGLE SOURCE OF TRUTH\n",
    "documents = [\n",
    "    {\n",
    "        \"id\": int(row[\"review_id\"]),\n",
    "        \"score\": float(row[\"score\"]),\n",
    "        \"text\": build_review_document(row),\n",
    "    }\n",
    "    for row in sample_docs.to_dicts()\n",
    "]\n",
    "\n",
    "print(\"Total stratified documents:\", len(documents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "73c2c2fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New vector store built\n"
     ]
    }
   ],
   "source": [
    "## STEP 3F â€” REBUILD VECTOR STORE (NEW COLLECTION)\n",
    "'''\n",
    "âš ï¸ Use a new collection name to avoid contamination.\n",
    "'''\n",
    "\n",
    "langchain_docs = [\n",
    "    Document(\n",
    "        page_content=doc[\"text\"],\n",
    "        metadata={\"review_id\": doc[\"id\"]}\n",
    "    )\n",
    "    for doc in documents\n",
    "]\n",
    "\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=langchain_docs,\n",
    "    embedding=embeddings,\n",
    "    collection_name=\"review_rag_complaints_v1\"\n",
    ")\n",
    "\n",
    "print(\"New vector store built\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "97da4a54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Result 1\n",
      "Review Type: Negative review\n",
      "Review Topic: ComputerGame\n",
      "Score: 1.0\n",
      "Review Text: Too many app crush\n",
      "\n",
      "Result 2\n",
      "Review Type: Negative review\n",
      "Review Topic: ComputerGame\n",
      "Score: 1.0\n",
      "Review Text: Too many app crush\n",
      "\n",
      "Result 3\n",
      "Review Type: Negative review\n",
      "Review Topic: ComputerGame\n",
      "Score: 1.0\n",
      "Review Text: Too many app crush\n",
      "\n",
      "Result 4\n",
      "Review Type: Negative review\n",
      "Review Topic: ComputerGame\n",
      "Score: 1.0\n",
      "Review Text: Too many app crush\n",
      "\n",
      "Result 5\n",
      "Review Type: Negative review\n",
      "Review Topic: ComputerGame\n",
      "Score: 1.0\n",
      "Review Text: Too many app crush\n"
     ]
    }
   ],
   "source": [
    "## STEP 3G â€” RETEST RETRIEVAL (MOST IMPORTANT)\n",
    "query = \"complaints about mobile games\"\n",
    "\n",
    "results = vectorstore.similarity_search(query, k=5)\n",
    "\n",
    "for i, res in enumerate(results, 1):\n",
    "    print(f\"\\nResult {i}\")\n",
    "    print(res.page_content[:400])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6b258b28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative docs: 3000\n",
      "General docs: 5000\n"
     ]
    }
   ],
   "source": [
    "## STEP 3H â€” Split Vector Stores by Sentiment (Safe Version)\n",
    "negative_docs = [\n",
    "    Document(\n",
    "        page_content=doc[\"text\"],\n",
    "        metadata={\"review_id\": doc[\"id\"], \"score\": doc[\"score\"]},\n",
    "    )\n",
    "    for doc in documents\n",
    "    if doc[\"score\"] <= 2.0\n",
    "]\n",
    "\n",
    "general_docs = [\n",
    "    Document(\n",
    "        page_content=doc[\"text\"],\n",
    "        metadata={\"review_id\": doc[\"id\"], \"score\": doc[\"score\"]},\n",
    "    )\n",
    "    for doc in documents\n",
    "]\n",
    "\n",
    "print(\"Negative docs:\", len(negative_docs))\n",
    "print(\"General docs:\", len(general_docs))\n",
    "\n",
    "# Safety fallback\n",
    "if len(negative_docs) == 0:\n",
    "    print(\"[WARN] No negative documents found. Falling back to general store.\")\n",
    "    negative_docs = general_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8e98adf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Both vector stores created\n"
     ]
    }
   ],
   "source": [
    "## create 2 vector stores\n",
    "\n",
    "negative_vectorstore = Chroma.from_documents(\n",
    "    documents=negative_docs,\n",
    "    embedding=embeddings,\n",
    "    collection_name=\"review_rag_negative_v1\",\n",
    ")\n",
    "\n",
    "general_vectorstore = Chroma.from_documents(\n",
    "    documents=general_docs,\n",
    "    embedding=embeddings,\n",
    "    collection_name=\"review_rag_general_v1\",\n",
    ")\n",
    "\n",
    "print(\"Both vector stores created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Retriever] Avg similarity @k=5: 0.840\n",
      "\n",
      "Result 1\n",
      "Review Type: Negative review\n",
      "Review Topic: ComputerGame\n",
      "Score: 1.0\n",
      "Review Text: Worst game ever\n",
      "\n",
      "Result 2\n",
      "Review Type: Negative review\n",
      "Review Topic: ComputerGame\n",
      "Score: 1.0\n",
      "Review Text: Worst game ever\n",
      "\n",
      "Result 3\n",
      "Review Type: Negative review\n",
      "Review Topic: ComputerGame\n",
      "Score: 1.0\n",
      "Review Text: Worst game ever\n",
      "\n",
      "Result 4\n",
      "Review Type: Negative review\n",
      "Review Topic: ComputerGame\n",
      "Score: 1.0\n",
      "Review Text: Worst game ever\n",
      "\n",
      "Result 5\n",
      "Review Type: Negative review\n",
      "Review Topic: ComputerGame\n",
      "Score: 1.0\n",
      "Review Text: Worst game ever\n"
     ]
    }
   ],
   "source": [
    "# STEP 3I â€” INTENT-AWARE RETRIEVAL (Dynamic k)\n",
    "\n",
    "query = \"complaints about Computer games\"\n",
    "\n",
    "INITIAL_K = 5\n",
    "MAX_K = 10\n",
    "SIMILARITY_THRESHOLD = 0.65\n",
    "\n",
    "# 1ï¸âƒ£ First pass retrieval\n",
    "results_with_scores = negative_vectorstore.similarity_search_with_score(\n",
    "    query, k=INITIAL_K\n",
    ")\n",
    "\n",
    "avg_similarity = sum(score for _, score in results_with_scores) / len(\n",
    "    results_with_scores\n",
    ")\n",
    "\n",
    "print(f\"[Retriever] Avg similarity @k={INITIAL_K}: {avg_similarity:.3f}\")\n",
    "\n",
    "# 2ï¸âƒ£ Expand search if similarity is weak\n",
    "if avg_similarity < SIMILARITY_THRESHOLD:\n",
    "    print(\"[Retriever] Low similarity detected. Expanding search...\")\n",
    "    results_with_scores = negative_vectorstore.similarity_search_with_score(\n",
    "        query, k=MAX_K\n",
    "    )\n",
    "\n",
    "# 3ï¸âƒ£ Final results\n",
    "final_results = [doc for doc, _ in results_with_scores]\n",
    "\n",
    "for i, res in enumerate(final_results, 1):\n",
    "    print(f\"\\nResult {i}\")\n",
    "    print(res.page_content[:400])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37a1cb50",
   "metadata": {},
   "source": [
    "## STEP 4 â€” CONVERSATIONAL ORCHESTRATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d85181",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install autogen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb9e191",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install autogen-agentchat autogen-ext sentence-transformers chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0b3d4d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import asyncio\n",
    "from dotenv import load_dotenv\n",
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_agentchat.conditions import MaxMessageTermination\n",
    "from autogen_agentchat.teams import RoundRobinGroupChat\n",
    "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "groq_api_key = os.getenv('GROQCLOUD_API_KEY')\n",
    "\n",
    "if not groq_api_key:\n",
    "    raise ValueError(\"GROQCLOUD_API_KEY not found in .env file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d7f33dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "groq_model_info = {\n",
    "    \"vision\": False,\n",
    "    \"function_calling\": True,\n",
    "    \"json_output\": True,\n",
    "    \"family\": \"unknown\",\n",
    "    \"structured_output\": False\n",
    "}\n",
    "\n",
    "model_client = OpenAIChatCompletionClient(\n",
    "    model=\"llama-3.3-70b-versatile\",\n",
    "    api_key=groq_api_key,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",\n",
    "    model_info=groq_model_info\n",
    ")\n",
    "\n",
    "# Utility / lightweight model\n",
    "utility_model_client = OpenAIChatCompletionClient(\n",
    "    model=\"llama-3.1-8b-instant\",\n",
    "    api_key=groq_api_key,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",\n",
    "    model_info=groq_model_info\n",
    ")\n",
    "\n",
    "# Reasoning / decision model\n",
    "reasoning_model_client = OpenAIChatCompletionClient(\n",
    "    model=\"llama-3.3-70b-versatile\",\n",
    "    api_key=groq_api_key,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",\n",
    "    model_info=groq_model_info,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "74003c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_reviews(query: str, top_k: int = 8) -> str:\n",
    "    \"\"\"Retrieve relevant reviews with deduplication\"\"\"\n",
    "    results = negative_vectorstore.similarity_search(query, k=top_k * 2)\n",
    "\n",
    "    seen = set()\n",
    "    unique_reviews = []\n",
    "\n",
    "    for doc in results:\n",
    "        text = doc.page_content.strip()\n",
    "        if text not in seen:\n",
    "            seen.add(text)\n",
    "            unique_reviews.append(text)\n",
    "        if len(unique_reviews) >= top_k:\n",
    "            break\n",
    "\n",
    "    formatted = \"\\n\\n---\\n\\n\".join([\n",
    "        f\"Review {i+1}:\\n{text}\"\n",
    "        for i, text in enumerate(unique_reviews)\n",
    "    ])\n",
    "\n",
    "    return (\n",
    "        f\"Found {len(unique_reviews)} unique complaint reviews \"\n",
    "        f\"(deduplicated from {len(results)} retrieved):\\n\\n{formatted}\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "20da0b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## STEP 5: Define Agents\n",
    "\n",
    "retriever_agent = AssistantAgent(\n",
    "    name=\"Retriever\",\n",
    "    model_client=utility_model_client,\n",
    "    system_message=\"\"\"You are a review retrieval specialist.\n",
    "    Use the retrieve_reviews tool to find relevant customer reviews.\n",
    "    Present the reviews clearly without analyzing them.\"\"\",\n",
    "    tools=[retrieve_reviews],\n",
    ")\n",
    "\n",
    "analyzer_agent = AssistantAgent(\n",
    "    name=\"Analyzer\",\n",
    "    model_client=reasoning_model_client,\n",
    "    system_message=\"\"\"You are a sentiment analysis expert.\n",
    "    Analyze the reviews provided by the Retriever.\n",
    "    Identify:\n",
    "    - Overall sentiment (positive/negative/neutral)\n",
    "    - Key themes and patterns\n",
    "    - Specific pain points\n",
    "    - Severity of issues\"\"\",\n",
    ")\n",
    "\n",
    "categorizer_agent = AssistantAgent(\n",
    "    name=\"Categorizer\",\n",
    "    model_client=utility_model_client,\n",
    "    system_message=\"\"\"You categorize customer complaints into themes:\n",
    "    - Performance Issues (lag, crashes, freezes)\n",
    "    - Monetization (ads, pay-to-win, pricing)\n",
    "    - Technical Problems (bugs, battery drain)\n",
    "    - UI/UX Problems (confusing interface, navigation)\n",
    "    - Customer Service\n",
    "    \n",
    "    Provide counts and priority levels for each category.\"\"\",\n",
    ")\n",
    "\n",
    "summarizer_agent = AssistantAgent(\n",
    "    name=\"Summarizer\",\n",
    "    model_client=utility_model_client,\n",
    "    system_message=\"\"\"You create executive summaries with:\n",
    "    - Top 3 critical issues\n",
    "    - Overall sentiment breakdown\n",
    "    - Actionable recommendations\n",
    "    - Priority rankings\"\"\",\n",
    ")\n",
    "\n",
    "decision_agent = AssistantAgent(\n",
    "    name=\"DecisionMaker\",\n",
    "    model_client=reasoning_model_client,\n",
    "    system_message=\"\"\"\n",
    "        You are a Lead Business Analyst.\n",
    "\n",
    "        Your task has TWO phases:\n",
    "\n",
    "        PHASE 1 â€” THINKING (PRIVATE)\n",
    "        - Carefully read all information from previous agents\n",
    "        - List key evidence points\n",
    "        - Check if evidence is sufficient\n",
    "        - Identify uncertainties or gaps\n",
    "        - Decide conservatively if evidence is weak\n",
    "\n",
    "        PHASE 2 â€” FINAL OUTPUT (PUBLIC)\n",
    "        - Output STRICT JSON ONLY\n",
    "        - Do NOT include explanations outside JSON\n",
    "        - Do NOT mention other agents\n",
    "        - Base everything ONLY on retrieved reviews\n",
    "        - If evidence is limited, lower confidence_level\n",
    "\n",
    "        IMPORTANT FORMAT RULES:\n",
    "        - First output a <THINKING>...</THINKING> block\n",
    "        - Then output <FINAL_JSON>...</FINAL_JSON>\n",
    "        - NOTHING after FINAL_JSON\n",
    "\n",
    "        Required JSON schema:\n",
    "\n",
    "        {\n",
    "        \"topic\": \"<review topic>\",\n",
    "        \"analysis_scope\": \"<e.g. Negative reviews only>\",\n",
    "        \"evidence_count\": <number>,\n",
    "        \"confidence_level\": \"<High | Medium | Low>\",\n",
    "        \"primary_issue\": \"<main problem identified>\",\n",
    "        \"evidence\": [\n",
    "            \"<short quote or paraphrase from review>\"\n",
    "        ],\n",
    "        \"root_causes\": [\n",
    "            \"<cause 1>\",\n",
    "            \"<cause 2>\"\n",
    "        ],\n",
    "        \"business_impact\": [\n",
    "            \"<impact 1>\",\n",
    "            \"<impact 2>\"\n",
    "        ],\n",
    "        \"recommended_actions\": [\n",
    "            \"<action 1>\",\n",
    "            \"<action 2>\"\n",
    "        ]\n",
    "        }\n",
    "        \"\"\",\n",
    ")\n",
    "\n",
    "critic_agent = AssistantAgent(\n",
    "    name=\"Critic\",\n",
    "    model_client=reasoning_model_client,\n",
    "    system_message=\"\"\"\n",
    "        You are a strict validation agent.\n",
    "\n",
    "        Your ONLY task is to validate the DecisionMaker's FINAL_JSON.\n",
    "\n",
    "        Rules:\n",
    "        - NEVER output JSON.\n",
    "        - NEVER repeat the DecisionMaker output.\n",
    "        - NEVER add new facts.\n",
    "\n",
    "        Validation checklist:\n",
    "        1. evidence_count must equal the number of items in \"evidence\".\n",
    "        2. Confidence calibration:\n",
    "        - evidence_count = 1 â†’ confidence must be Low\n",
    "        - evidence_count â‰¤ 2 â†’ confidence cannot be High\n",
    "        - evidence_count â‰¥ 10 â†’ confidence should NOT be Low\n",
    "        3. Evidence statements must be supported by retrieved reviews.\n",
    "        4. No new facts allowed.\n",
    "\n",
    "        Output format (STRICT, ONE OF TWO):\n",
    "\n",
    "        If valid:\n",
    "        APPROVED\n",
    "\n",
    "        If invalid:\n",
    "        ERROR:\n",
    "        - <one-line explanation>\n",
    "        - <what must be changed>\n",
    "\n",
    "        Do not output anything else.\n",
    "        \"\"\"\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "team = RoundRobinGroupChat(\n",
    "    participants=[\n",
    "        retriever_agent,\n",
    "        analyzer_agent,\n",
    "        categorizer_agent,\n",
    "        summarizer_agent,\n",
    "        decision_agent,\n",
    "        critic_agent,\n",
    "    ],\n",
    "    termination_condition=MaxMessageTermination(max_messages=6),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f8b88596",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def run_analysis(query: str):\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"QUERY:\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "\n",
    "    # First run\n",
    "    result = await team.run(task=query)\n",
    "\n",
    "    decision_json = None\n",
    "    critic_verdict = None\n",
    "\n",
    "    for msg in result.messages:\n",
    "        if msg.source == \"DecisionMaker\":\n",
    "            decision_json = msg.content\n",
    "        elif msg.source == \"Critic\":\n",
    "            critic_verdict = msg.content\n",
    "\n",
    "    # If approved, finish\n",
    "    if critic_verdict and critic_verdict.strip() == \"APPROVED\":\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(\"FINAL DECISION (APPROVED)\")\n",
    "        print(f\"{'='*80}\\n\")\n",
    "        print(decision_json)\n",
    "        return result\n",
    "\n",
    "    # If error, allow ONE correction\n",
    "    if critic_verdict and critic_verdict.startswith(\"ERROR\"):\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(\"CRITIC FOUND ISSUES â€” AUTO-CORRECTING ONCE\")\n",
    "        print(f\"{'='*80}\\n\")\n",
    "        print(critic_verdict)\n",
    "\n",
    "        correction_prompt = f\"\"\"\n",
    "The Critic has found issues in your previous decision:\n",
    "\n",
    "{critic_verdict}\n",
    "\n",
    "Please FIX the issues and output a corrected FINAL_JSON.\n",
    "Follow the same schema.\n",
    "Do not add new evidence.\n",
    "\"\"\"\n",
    "\n",
    "        # Second run: ONLY DecisionMaker + Critic\n",
    "        correction_team = RoundRobinGroupChat(\n",
    "            participants=[decision_agent, critic_agent],\n",
    "            termination_condition=MaxMessageTermination(max_messages=2),\n",
    "        )\n",
    "\n",
    "        corrected_result = await correction_team.run(task=correction_prompt)\n",
    "\n",
    "        corrected_decision = None\n",
    "        corrected_verdict = None\n",
    "\n",
    "        for msg in corrected_result.messages:\n",
    "            if msg.source == \"DecisionMaker\":\n",
    "                corrected_decision = msg.content\n",
    "            elif msg.source == \"Critic\":\n",
    "                corrected_verdict = msg.content\n",
    "\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(\"FINAL DECISION (AFTER CORRECTION)\")\n",
    "        print(f\"{'='*80}\\n\")\n",
    "        print(corrected_decision)\n",
    "\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(\"FINAL CRITIC VERDICT\")\n",
    "        print(f\"{'='*80}\\n\")\n",
    "        print(corrected_verdict)\n",
    "\n",
    "        return corrected_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "56cdc456",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "QUERY:\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "FINAL DECISION (APPROVED)\n",
      "================================================================================\n",
      "\n",
      "<THINKING> \n",
      "The customer reviews about the computer game are overwhelmingly negative, with concerns about game quality, pricing, and mobile data usage. \n",
      "The analysis highlights specific pain points, including poor game quality, expensive pricing, and high mobile data usage. \n",
      "The evidence is sufficient to support the conclusion that the game requires significant improvements to address customer concerns. \n",
      "The primary issues identified are poor game quality, expensive pricing, and high mobile data usage. \n",
      "The root causes of these issues are likely related to game development, pricing strategy, and data optimization. \n",
      "The business impact of these issues is significant, with potential consequences including negative word-of-mouth, decreased customer satisfaction, and reduced sales. \n",
      "The recommended actions are to reinvest in game development, optimize mobile data usage, and price competitively. \n",
      "</THINKING> \n",
      "\n",
      "<FINAL_JSON>\n",
      "{\n",
      "  \"topic\": \"Computer Game Complaints\",\n",
      "  \"analysis_scope\": \"Negative reviews only\",\n",
      "  \"evidence_count\": 3,\n",
      "  \"confidence_level\": \"Low\",\n",
      "  \"primary_issue\": \"Poor Game Quality and Expensive Pricing\",\n",
      "  \"evidence\": [\n",
      "    \"Worst game ever\",\n",
      "    \"This game is way too expensive for Americans. It's a scam. The prices are too high. The cost of living in America is high enough as it is.\",\n",
      "    \"I don't like this game because it's carry most of mobile data but it's feature is very low and so simple and boring\"\n",
      "  ],\n",
      "  \"root_causes\": [\n",
      "    \"Inadequate game development\",\n",
      "    \"Poor pricing strategy\",\n",
      "    \"Inefficient data optimization\"\n",
      "  ],\n",
      "  \"business_impact\": [\n",
      "    \"Negative word-of-mouth\",\n",
      "    \"Decreased customer satisfaction\",\n",
      "    \"Reduced sales\"\n",
      "  ],\n",
      "  \"recommended_actions\": [\n",
      "    \"Reinvest in game development to improve game quality\",\n",
      "    \"Optimize mobile data usage to reduce data consumption\",\n",
      "    \"Price competitively to address customer concerns about expensive pricing\"\n",
      "  ]\n",
      "}\n",
      "</FINAL_JSON>\n"
     ]
    }
   ],
   "source": [
    "queries =\"\"\"\n",
    "        Retrieve relevant customer reviews about Computer game complaints.\n",
    "        Analyze them to identify recurring issues.\n",
    "        Categorize the issues.\n",
    "        Then produce ONE final business summary with recommendations.\n",
    "        \"\"\"\n",
    "\n",
    "# Run first query\n",
    "result = await run_analysis(queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f27d89",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai-project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
